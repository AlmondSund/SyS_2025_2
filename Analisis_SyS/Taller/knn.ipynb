{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a98b1711",
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "KNN genre detector optimized for environments with librosa installed.\n",
        "- Audio IO/processing via librosa only (no fallbacks).\n",
        "- Feature: average magnitude spectrum from STFT (Hann), then L2 normalize.\n",
        "- Distance: Euclidean; fast k-NN using argpartition.\n",
        "- Parallel feature extraction with joblib.\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "import os\n",
        "import json\n",
        "import hashlib\n",
        "from dataclasses import dataclass, asdict\n",
        "from pathlib import Path\n",
        "from typing import List, Tuple, Optional, Dict, Any\n",
        "from urllib.parse import urlparse\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from joblib import dump, load, Parallel, delayed\n",
        "import librosa\n",
        "\n",
        "try:\n",
        "    import yt_dlp\n",
        "except ImportError:  # pragma: no cover - fallback cuando no se usarán URLs\n",
        "    yt_dlp = None\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class SpectralConfig:\n",
        "    sr: int = 22050\n",
        "    duration: float = 5.0\n",
        "    n_fft: int = 4096\n",
        "    hop_length: int = 2048\n",
        "    k: int = 5\n",
        "    res_type: str = \"soxr_vhq\"\n",
        "    l2_normalize: bool = True\n",
        "    center_stft: bool = False   # center=False avoids extra padding and is a bit faster\n",
        "    n_jobs: int = -1            # parallelism for feature extraction\n",
        "    eps: float = 1e-12\n",
        "    audio_cache_dir: str = \"audio_cache\"\n",
        "    ffmpeg_path: Optional[str] = None\n",
        "\n",
        "\n",
        "def _detect_columns(df: pd.DataFrame) -> Tuple[str, str]:\n",
        "    cols = {c.lower(): c for c in df.columns}\n",
        "    path_candidates = [\"path\", \"filepath\", \"file\", \"audio\", \"filename\", \"wav\", \"mp3\", \"ogg\", \"uri\", \"link\"]\n",
        "    label_candidates = [\"label\", \"genre\", \"class\", \"target\", \"y\", \"tag\"]\n",
        "    path_col = next((cols[c] for c in path_candidates if c in cols), None)\n",
        "    label_col = next((cols[c] for c in label_candidates if c in cols), None)\n",
        "    if path_col is None or label_col is None:\n",
        "        raise ValueError(\n",
        "            \"No pude detectar columnas de ruta y etiqueta. \"\n",
        "            \"Incluye ('path'/'filepath'/...) y ('label'/'genre'/...).\"\n",
        "        )\n",
        "    return path_col, label_col\n",
        "\n",
        "\n",
        "_AUDIO_EXT_PRIORITY = (\".wav\", \".flac\", \".ogg\", \".m4a\", \".mp3\", \".opus\", \".webm\")\n",
        "_NON_AUDIO_SUFFIXES = {\".json\", \".part\", \".ytdl\", \".info.json\", \".jpg\", \".jpeg\", \".png\"}\n",
        "\n",
        "\n",
        "def _looks_like_url(value: str) -> bool:\n",
        "    try:\n",
        "        parsed = urlparse(value)\n",
        "    except Exception:\n",
        "        return False\n",
        "    return parsed.scheme in {\"http\", \"https\"} and bool(parsed.netloc)\n",
        "\n",
        "\n",
        "def _pick_cached_audio(cache_dir: Path, key: str) -> Optional[Path]:\n",
        "    for ext in _AUDIO_EXT_PRIORITY:\n",
        "        candidate = cache_dir / f\"{key}{ext}\"\n",
        "        if candidate.exists():\n",
        "            return candidate\n",
        "    for ext in _AUDIO_EXT_PRIORITY:\n",
        "        for candidate in cache_dir.glob(f\"**/{key}{ext}\"):\n",
        "            if candidate.exists():\n",
        "                return candidate\n",
        "    for candidate in cache_dir.glob(f\"**/{key}.*\"):\n",
        "        suffix = candidate.suffix.lower()\n",
        "        if suffix not in _NON_AUDIO_SUFFIXES and candidate.exists():\n",
        "            return candidate\n",
        "    return None\n",
        "\n",
        "\n",
        "def _ensure_local_audio(path_or_url: str, cfg: SpectralConfig) -> str:\n",
        "    \"\"\"Devuelve una ruta local lista para librosa. Descarga desde YouTube si es necesario.\"\"\"\n",
        "    if os.path.exists(path_or_url):\n",
        "        return path_or_url\n",
        "\n",
        "    if not _looks_like_url(path_or_url):\n",
        "        raise FileNotFoundError(f\"No existe el archivo ni es una URL válida: {path_or_url}\")\n",
        "\n",
        "    if yt_dlp is None:\n",
        "        raise RuntimeError(\n",
        "            \"Se requiere 'yt_dlp' para descargar audio desde enlaces. Instálalo e inténtalo de nuevo.\"\n",
        "        )\n",
        "\n",
        "    cache_dir = Path(cfg.audio_cache_dir)\n",
        "    cache_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    cache_key = hashlib.sha1(path_or_url.encode(\"utf-8\")).hexdigest()\n",
        "    cached = _pick_cached_audio(cache_dir, cache_key)\n",
        "    if cached is not None:\n",
        "        return str(cached)\n",
        "\n",
        "    base_opts: Dict[str, Any] = {\n",
        "        \"format\": \"bestaudio/best\",\n",
        "        \"outtmpl\": str(cache_dir / f\"{cache_key}.%(ext)s\"),\n",
        "        \"noplaylist\": True,\n",
        "        \"quiet\": True,\n",
        "        \"no_warnings\": True,\n",
        "        \"restrictfilenames\": True,\n",
        "        \"retries\": 5,\n",
        "        \"fragment_retries\": 5,\n",
        "        \"overwrites\": False,\n",
        "        \"socket_timeout\": 20,\n",
        "    }\n",
        "    if cfg.ffmpeg_path:\n",
        "        base_opts[\"ffmpeg_location\"] = cfg.ffmpeg_path\n",
        "\n",
        "    download_attempts = [\n",
        "        {\n",
        "            **base_opts,\n",
        "            \"postprocessors\": [\n",
        "                {\"key\": \"FFmpegExtractAudio\", \"preferredcodec\": \"wav\", \"preferredquality\": \"192\"}\n",
        "            ],\n",
        "        },\n",
        "        dict(base_opts),\n",
        "    ]\n",
        "\n",
        "    last_error: Optional[Exception] = None\n",
        "    for opts in download_attempts:\n",
        "        try:\n",
        "            with yt_dlp.YoutubeDL(opts) as ydl:\n",
        "                ydl.download([path_or_url])\n",
        "            cached = _pick_cached_audio(cache_dir, cache_key)\n",
        "            if cached is not None:\n",
        "                return str(cached)\n",
        "        except Exception as err:  # pragma: no cover - depende de acceso a red/ffmpeg\n",
        "            last_error = err\n",
        "            continue\n",
        "\n",
        "    msg = f\"No se pudo descargar audio desde {path_or_url}\"\n",
        "    if last_error is not None:\n",
        "        msg += f\": {last_error}\"\n",
        "    raise RuntimeError(msg)\n",
        "\n",
        "\n",
        "def _load_audio(path: str, cfg: SpectralConfig) -> np.ndarray:\n",
        "    \"\"\"Load audio with librosa, mono, fixed 5s at cfg.sr.\"\"\"\n",
        "    # librosa.load trims or pads to duration if we fix length afterwards\n",
        "    y, _ = librosa.load(path, sr=cfg.sr, mono=True, res_type=cfg.res_type, duration=cfg.duration)\n",
        "    target_len = int(round(cfg.duration * cfg.sr))\n",
        "    if len(y) != target_len:\n",
        "        y = librosa.util.fix_length(y, target_len)  # pad/trim to exact length\n",
        "    # remove DC and normalize amplitude\n",
        "    y = y - float(np.mean(y))\n",
        "    maxabs = float(np.max(np.abs(y)) + cfg.eps)\n",
        "    y = (y / maxabs).astype(np.float32, copy=False)\n",
        "    return y\n",
        "\n",
        "\n",
        "def _spectral_feature(y: np.ndarray, cfg: SpectralConfig) -> np.ndarray:\n",
        "    \"\"\"Average magnitude spectrum from STFT with Hann window.\"\"\"\n",
        "    S = librosa.stft(\n",
        "        y,\n",
        "        n_fft=cfg.n_fft,\n",
        "        hop_length=cfg.hop_length,\n",
        "        window=\"hann\",\n",
        "        center=cfg.center_stft,\n",
        "    )  # shape: (n_bins, n_frames)\n",
        "    mag = np.abs(S).astype(np.float32, copy=False)\n",
        "    feat = np.mean(mag, axis=1)  # (n_bins,)\n",
        "    if cfg.l2_normalize:\n",
        "        feat /= (np.linalg.norm(feat) + cfg.eps)\n",
        "    return feat.astype(np.float32, copy=False)\n",
        "\n",
        "\n",
        "def compute_feature_for_file(path: str, cfg: SpectralConfig) -> np.ndarray:\n",
        "    local_path = _ensure_local_audio(path, cfg)\n",
        "    y = _load_audio(local_path, cfg)\n",
        "    return _spectral_feature(y, cfg)\n",
        "\n",
        "\n",
        "def _euclidean(a: np.ndarray, b: np.ndarray) -> float:\n",
        "    return float(np.linalg.norm(a - b))\n",
        "\n",
        "\n",
        "class KNNSpectralClassifier:\n",
        "    def __init__(self, cfg: Optional[SpectralConfig] = None):\n",
        "        self.cfg = cfg or SpectralConfig()\n",
        "        self.X: Optional[np.ndarray] = None  # (N, D), float32\n",
        "        self.labels: List[str] = []\n",
        "        self.paths: List[str] = []\n",
        "        self.sources: List[str] = []\n",
        "        self.meta: Dict[str, Any] = {}\n",
        "\n",
        "    def fit_from_dataframe(\n",
        "        self, df: pd.DataFrame, path_col: Optional[str] = None, label_col: Optional[str] = None\n",
        "    ) -> \"KNNSpectralClassifier\":\n",
        "        pcol, lcol = (path_col, label_col) if (path_col and label_col) else _detect_columns(df)\n",
        "\n",
        "        pairs: List[Tuple[str, str]] = []\n",
        "        sources: List[str] = []\n",
        "        failed: List[Dict[str, str]] = []\n",
        "        for _, row in df.iterrows():\n",
        "            raw_path = str(row[pcol])\n",
        "            label = str(row[lcol])\n",
        "            try:\n",
        "                local_path = _ensure_local_audio(raw_path, self.cfg)\n",
        "            except Exception as exc:  # pragma: no cover - depende de acceso a red\n",
        "                failed.append({\"source\": raw_path, \"error\": str(exc)})\n",
        "                continue\n",
        "            pairs.append((local_path, label))\n",
        "            sources.append(raw_path)\n",
        "\n",
        "        if not pairs:\n",
        "            raise RuntimeError(\"No se encontraron rutas de audio existentes en el CSV.\")\n",
        "\n",
        "        # Parallel feature extraction\n",
        "        feats = Parallel(n_jobs=self.cfg.n_jobs, prefer=\"threads\")(\n",
        "            delayed(compute_feature_for_file)(p, self.cfg) for (p, _) in pairs\n",
        "        )\n",
        "\n",
        "        self.X = np.ascontiguousarray(np.stack(feats).astype(np.float32, copy=False))\n",
        "        self.labels = [lab for (_, lab) in pairs]\n",
        "        self.paths = [p for (p, _) in pairs]\n",
        "        self.sources = sources\n",
        "        self.meta = {\n",
        "            \"config\": asdict(self.cfg),\n",
        "            \"path_column\": pcol,\n",
        "            \"label_column\": lcol,\n",
        "            \"failed_sources\": failed,\n",
        "        }\n",
        "        return self\n",
        "\n",
        "    def kneighbors(self, x: np.ndarray, k: Optional[int] = None):\n",
        "        if self.X is None:\n",
        "            raise RuntimeError(\"Modelo vacío. Llama fit_from_dataframe primero o load().\")\n",
        "        k = int(k or self.cfg.k)\n",
        "        # compute all distances (vectorized); float32 for speed\n",
        "        diff = self.X - x[None, :].astype(self.X.dtype, copy=False)\n",
        "        dists = np.sqrt(np.sum(diff * diff, axis=1, dtype=np.float32))\n",
        "        # fast top-k selection\n",
        "        if k < len(dists):\n",
        "            idxs = np.argpartition(dists, k)[:k]\n",
        "            idxs = idxs[np.argsort(dists[idxs])]\n",
        "        else:\n",
        "            idxs = np.argsort(dists)\n",
        "        neighbors = []\n",
        "        for i in idxs[:k]:\n",
        "            idx = int(i)\n",
        "            neighbors.append(\n",
        "                {\n",
        "                    \"idx\": idx,\n",
        "                    \"path\": self.paths[idx],\n",
        "                    \"source\": self.sources[idx] if idx < len(self.sources) else self.paths[idx],\n",
        "                    \"label\": self.labels[idx],\n",
        "                    \"distance\": float(dists[idx]),\n",
        "                }\n",
        "            )\n",
        "        return neighbors\n",
        "\n",
        "    def predict(self, path: str, k: Optional[int] = None):\n",
        "        resolved_path = _ensure_local_audio(path, self.cfg)\n",
        "        x = compute_feature_for_file(resolved_path, self.cfg)\n",
        "        neighbors = self.kneighbors(x, k=k)\n",
        "        # Majority vote with nearest-neighbor tie-break\n",
        "        counts: Dict[str, int] = {}\n",
        "        for nb in neighbors:\n",
        "            counts[nb[\"label\"]] = counts.get(nb[\"label\"], 0) + 1\n",
        "        max_count = max(counts.values())\n",
        "        cands = [lbl for lbl, c in counts.items() if c == max_count]\n",
        "        pred = cands[0] if len(cands) == 1 else neighbors[0][\"label\"]\n",
        "        probs = {lbl: counts.get(lbl, 0) / len(neighbors) for lbl in set(self.labels)}\n",
        "        return pred, neighbors, probs, resolved_path\n",
        "\n",
        "    def save(self, path: str) -> None:\n",
        "        if self.X is None:\n",
        "            raise RuntimeError(\"Nada que guardar: X es None.\")\n",
        "        dump(\n",
        "            {\n",
        "                \"X\": self.X,\n",
        "                \"labels\": self.labels,\n",
        "                \"paths\": self.paths,\n",
        "                \"sources\": self.sources,\n",
        "                \"meta\": self.meta,\n",
        "            },\n",
        "            path,\n",
        "        )\n",
        "\n",
        "    def load(self, path: str) -> \"KNNSpectralClassifier\":\n",
        "        payload = load(path)\n",
        "        self.X = payload[\"X\"]\n",
        "        self.labels = list(payload[\"labels\"])\n",
        "        self.paths = list(payload[\"paths\"])\n",
        "        self.sources = list(payload.get(\"sources\", []))\n",
        "        self.meta = dict(payload.get(\"meta\", {}))\n",
        "        if \"config\" in self.meta:\n",
        "            try:\n",
        "                self.cfg = SpectralConfig(**self.meta[\"config\"])\n",
        "            except Exception:\n",
        "                pass\n",
        "        return self\n",
        "\n",
        "\n",
        "def auto_fit_and_save(\n",
        "    csv_path: str,\n",
        "    out_model_path: str,\n",
        "    path_col: Optional[str] = None,\n",
        "    label_col: Optional[str] = None,\n",
        "    cfg_overrides: Optional[Dict[str, Any]] = None,\n",
        ") -> str:\n",
        "    cfg = SpectralConfig(**(cfg_overrides or {}))\n",
        "    df = pd.read_csv(csv_path)\n",
        "    clf = KNNSpectralClassifier(cfg)\n",
        "    clf.fit_from_dataframe(df, path_col=path_col, label_col=label_col)\n",
        "    clf.save(out_model_path)\n",
        "    return out_model_path\n",
        "\n",
        "\n",
        "def classify_with_model(model_path: str, audio_path: str, k: Optional[int] = None) -> Dict[str, Any]:\n",
        "    clf = KNNSpectralClassifier().load(model_path)\n",
        "    pred, neighbors, probs, resolved_path = clf.predict(audio_path, k=k)\n",
        "    return {\n",
        "        \"predicted_label\": pred,\n",
        "        \"neighbors\": neighbors,\n",
        "        \"vote_probs\": probs,\n",
        "        \"resolved_audio_path\": resolved_path,\n",
        "        \"config\": clf.meta.get(\"config\", {}),\n",
        "    }\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    import argparse\n",
        "\n",
        "    parser = argparse.ArgumentParser(description=\"KNN detector de género musical por espectro (librosa).\")\n",
        "    parser.add_argument(\"--dataset\", type=str, help=\"Ruta al CSV con columnas de rutas y etiquetas.\")\n",
        "    parser.add_argument(\"--path-col\", type=str, default=None, help=\"Nombre de la columna de ruta.\")\n",
        "    parser.add_argument(\"--label-col\", type=str, default=None, help=\"Nombre de la columna de etiqueta/género.\")\n",
        "    parser.add_argument(\"--out-model\", type=str, default=\"knn_model.joblib\", help=\"Ruta de salida del modelo.\")\n",
        "    parser.add_argument(\"--sr\", type=int, default=22050)\n",
        "    parser.add_argument(\"--duration\", type=float, default=5.0)\n",
        "    parser.add_argument(\"--n-fft\", type=int, default=4096)\n",
        "    parser.add_argument(\"--hop-length\", type=int, default=2048)\n",
        "    parser.add_argument(\"--k\", type=int, default=5)\n",
        "    parser.add_argument(\"--center-stft\", action=\"store_true\", help=\"Usa center=True en STFT (por defecto False).\")\n",
        "    parser.add_argument(\"--n-jobs\", type=int, default=-1, help=\"Paralelismo en extracción de features.\")\n",
        "    parser.add_argument(\n",
        "        \"--cache-dir\",\n",
        "        type=str,\n",
        "        default=None,\n",
        "        help=\"Directorio local para cachear audios descargados (por defecto ./audio_cache).\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--ffmpeg\",\n",
        "        type=str,\n",
        "        default=None,\n",
        "        help=\"Ruta al binario de ffmpeg si no está disponible en PATH (opcional).\",\n",
        "    )\n",
        "    parser.add_argument(\"--classify\", type=str, default=None, help=\"Ruta a un audio de 5s para clasificar.\")\n",
        "    parser.add_argument(\"--k-infer\", type=int, default=None, help=\"k a usar en inferencia.\")\n",
        "\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    cfg_over = dict(\n",
        "        sr=args.sr,\n",
        "        duration=args.duration,\n",
        "        n_fft=args.n_fft,\n",
        "        hop_length=args.hop_length,\n",
        "        k=args.k,\n",
        "        center_stft=args.center_stft,\n",
        "        n_jobs=args.n_jobs,\n",
        "    )\n",
        "    if args.cache_dir:\n",
        "        cfg_over[\"audio_cache_dir\"] = args.cache_dir\n",
        "    if args.ffmpeg:\n",
        "        cfg_over[\"ffmpeg_path\"] = args.ffmpeg\n",
        "\n",
        "    if args.dataset:\n",
        "        model_path = auto_fit_and_save(\n",
        "            csv_path=args.dataset,\n",
        "            out_model_path=args.out_model,\n",
        "            path_col=args.path_col,\n",
        "            label_col=args.label_col,\n",
        "            cfg_overrides=cfg_over,\n",
        "        )\n",
        "        print(f\"[ok] Modelo guardado en: {model_path}\")\n",
        "\n",
        "    if args.classify:\n",
        "        if not os.path.exists(args.out_model):\n",
        "            raise SystemExit(f\"Modelo no encontrado: {args.out_model}\")\n",
        "        result = classify_with_model(args.out_model, args.classify, k=args.k_infer)\n",
        "        print(json.dumps(result, indent=2, ensure_ascii=False))\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
