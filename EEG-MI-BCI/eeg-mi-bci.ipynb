{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3e587d3a",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "<div align=\"center\">\n",
        "\n",
        "### **FINAL PROJECT - SIGNALS AND SYSTEMS - 2025 2S**\n",
        "#### **Group members:** Martín Ramírez Espinosa, Valeria Corredor García\n",
        "##### Department of Electrical, Electronic and Computer Engineering\n",
        "##### National University of Colombia - Manizales Campus\n",
        "\n",
        "</div>\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d6f6d8f",
      "metadata": {},
      "source": [
        "**Objective.** Implement time- and frequency-domain representation techniques for recognizing electroencephalography (EEG) signals in motor imagery tasks.\n",
        "\n",
        "<p align=\"center\"><img src=\"https://figures.semanticscholar.org/288a54f091264377eccc99a19079c9387d66a78f/3-Figure2-1.png\" alt=\"Motor imagery EEG example\" style=\"max-width:50%; width:50%;\"></p>\n",
        "\n",
        "EEG signals can be noisy due to various sources, including physiological artifacts and electromagnetic interference. They also vary from person to person, which complicates feature extraction and interpretation. Moreover, this variability—shaped by genetic and cognitive factors—poses challenges for developing subject-independent solutions.\n",
        "\n",
        "**Database:** GiGaScience Database [https://gigadb.org/dataset/100295](https://gigadb.org/dataset/100295)\n",
        "\n",
        "See Section 3.1 in [Multimodal Explainability Using Class Activation Maps and Canonical Correlation for MI-EEG Deep Learning Classification](https://www.mdpi.com/2076-3417/14/23/11208).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c25240b",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6674f6ec",
      "metadata": {},
      "source": [
        "**Setup.** Install the necessary libraries.\n",
        "\n",
        "**Exercise 1.** Investigate the purpose of the following libraries.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "679b2f85",
      "metadata": {},
      "outputs": [],
      "source": [
        "#!pip install tensorflow==2.15.0\n",
        "!pip install mne==1.6.0\n",
        "!pip install braindecode===0.7\n",
        "!pip install -U git+https://github.com/UN-GCPDS/python-gcpds.databases\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25ddb154",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4994c23",
      "metadata": {},
      "source": [
        "**Imports.** Import the required libraries.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86bcb522",
      "metadata": {},
      "outputs": [],
      "source": [
        "from scipy.signal import resample\n",
        "from scipy.signal import freqz, filtfilt, resample\n",
        "from scipy.signal import butter as bw\n",
        "import pandas as pd\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# import tensorflow as tf\n",
        "from gcpds.databases import GIGA_MI_ME\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c8471c2",
      "metadata": {},
      "source": [
        "**Preprocessing helpers.** Functions needed for light preprocessing of the data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b020872",
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_GIGA(db, sbj, eeg_ch_names, new_fs, fs, f_bank=None, vwt=None, run=None):\n",
        "    index_eeg_chs = db.format_channels_selectors(channels=eeg_ch_names) - 1\n",
        "\n",
        "    # tf_repr = TimeFrequencyRpr(sfreq = fs, f_bank = f_bank, vwt = vwt)\n",
        "\n",
        "    db.load_subject(sbj)\n",
        "    if run == None:\n",
        "        X, y = db.get_data(\n",
        "            classes=[\"left hand mi\", \"right hand mi\"]\n",
        "        )  # Load MI classes, all channels {EEG}, reject bad trials, uV\n",
        "    else:\n",
        "        X, y = db.get_run(\n",
        "            run, classes=[\"left hand mi\", \"right hand mi\"]\n",
        "        )  # Load MI classes, all channels {EEG}, reject bad trials, uV\n",
        "    X = X[:, index_eeg_chs, :]  # spatial rearrangement\n",
        "    # X = np.squeeze(tf_repr.transform(X))\n",
        "    # Resampling\n",
        "    if new_fs == fs:\n",
        "        pass  # print('No resampling, since new sampling rate same.')\n",
        "    else:\n",
        "        print(\"Resampling from {:f} to {:f} Hz.\".format(fs, new_fs))\n",
        "        X = resample(X, int((X.shape[-1] / fs) * new_fs), axis=-1)\n",
        "\n",
        "    return X, y\n",
        "\n",
        "\n",
        "def butterworth_digital_filter(\n",
        "    X, N, Wn, btype, fs, axis=-1, padtype=None, padlen=0, method=\"pad\", irlen=None\n",
        "):\n",
        "    \"\"\"\n",
        "    Apply digital butterworth filter\n",
        "    INPUT\n",
        "    ------\n",
        "    1. X: (D array)\n",
        "      array with signals.\n",
        "    2. N: (int+)\n",
        "      The order of the filter.\n",
        "    3. Wn: (float+ or 1D array)\n",
        "      The critical frequency or frequencies. For lowpass and highpass filters, Wn is a scalar; for bandpass and bandstop filters, Wn is a length-2 vector.\n",
        "      For a Butterworth filter, this is the point at which the gain drops to 1/sqrt(2) that of the passband (the “-3 dB point”).\n",
        "      If fs is not specified, Wn units are normalized from 0 to 1, where 1 is the Nyquist frequency (Wn is thus in half cycles / sample and defined as 2*critical frequencies / fs). If fs is specified, Wn is in the same units as fs.\n",
        "    4. btype: (str) {‘lowpass’, ‘highpass’, ‘bandpass’, ‘bandstop’}\n",
        "      The type of filter\n",
        "    5. fs: (float+)\n",
        "      The sampling frequency of the digital system.\n",
        "    6. axis: (int), Default=1.\n",
        "      The axis of x to which the filter is applied.\n",
        "    7. padtype: (str) or None, {'odd', 'even', 'constant'}\n",
        "      This determines the type of extension to use for the padded signal to which the filter is applied. If padtype is None, no padding is used. The default is ‘odd’.\n",
        "    8. padlen: (int+) or None, Default=0\n",
        "      The number of elements by which to extend x at both ends of axis before applying the filter. This value must be less than x.shape[axis] - 1. padlen=0 implies no padding.\n",
        "    9. method: (str), {'pad', 'gust'}\n",
        "      Determines the method for handling the edges of the signal, either “pad” or “gust”. When method is “pad”, the signal is padded; the type of padding is determined by padtype\n",
        "      and padlen, and irlen is ignored. When method is “gust”, Gustafsson’s method is used, and padtype and padlen are ignored.\n",
        "    10. irlen: (int) or None, Default=nONE\n",
        "      When method is “gust”, irlen specifies the length of the impulse response of the filter. If irlen is None, no part of the impulse response is ignored.\n",
        "      For a long signal, specifying irlen can significantly improve the performance of the filter.\n",
        "    OUTPUT\n",
        "    ------\n",
        "    X_fil: (D array)\n",
        "      array with filtered signals.\n",
        "    \"\"\"\n",
        "    b, a = bw(N, Wn, btype, analog=False, output=\"ba\", fs=fs)\n",
        "    return filtfilt(\n",
        "        b, a, X, axis=axis, padtype=padtype, padlen=padlen, method=method, irlen=irlen\n",
        "    )\n",
        "\n",
        "\n",
        "class TimeFrequencyRpr(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    Time frequency representation of EEG signals.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "      1. sfreq:  (float) Sampling frequency in Hz.\n",
        "      2. f_bank: (2D array) Filter banks Frequencies. Default=None\n",
        "      3. vwt:    (2D array) Interest time windows. Default=None\n",
        "    Methods\n",
        "    -------\n",
        "      1. fit(X, y=None)\n",
        "      2. transform(X, y=None)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, sfreq, f_bank=None, vwt=None):\n",
        "        self.sfreq = sfreq\n",
        "        self.f_bank = f_bank\n",
        "        self.vwt = vwt\n",
        "\n",
        "    # ------------------------------------------------------------------------------\n",
        "\n",
        "    def _validation_param(self):\n",
        "        \"\"\"\n",
        "        Validate Time-Frequency characterization parameters.\n",
        "        INPUT\n",
        "        -----\n",
        "          1. self\n",
        "        ------\n",
        "          2. None\n",
        "        \"\"\"\n",
        "        if self.sfreq <= 0:\n",
        "            raise ValueError(\"Non negative sampling frequency is accepted\")\n",
        "\n",
        "        if self.f_bank is None:\n",
        "            self.flag_f_bank = False\n",
        "        elif self.f_bank.ndim != 2:\n",
        "            raise ValueError(\"Band frequencies have to be a 2D array\")\n",
        "        else:\n",
        "            self.flag_f_bank = True\n",
        "\n",
        "        if self.vwt is None:\n",
        "            self.flag_vwt = False\n",
        "        elif self.vwt.ndim != 2:\n",
        "            raise ValueError(\"Time windows have to be a 2D array\")\n",
        "        else:\n",
        "            self.flag_vwt = True\n",
        "\n",
        "    # ------------------------------------------------------------------------------\n",
        "    def _filter_bank(self, X):\n",
        "        \"\"\"\n",
        "        Filter bank Characterization.\n",
        "        INPUT\n",
        "        -----\n",
        "          1. X: (3D array) set of EEG signals, shape (trials, channels, time_samples)\n",
        "        OUTPUT\n",
        "        ------\n",
        "          1. X_f: (4D array) set of filtered EEG signals, shape (trials, channels, time_samples, frequency_bands)\n",
        "        \"\"\"\n",
        "        X_f = np.zeros(\n",
        "            (X.shape[0], X.shape[1], X.shape[2], self.f_bank.shape[0])\n",
        "        )  # epochs, Ch, Time, bands\n",
        "        for f in np.arange(self.f_bank.shape[0]):\n",
        "            X_f[:, :, :, f] = butterworth_digital_filter(\n",
        "                X, N=5, Wn=self.f_bank[f], btype=\"bandpass\", fs=self.sfreq\n",
        "            )\n",
        "        return X_f\n",
        "\n",
        "    # ------------------------------------------------------------------------------\n",
        "    def _sliding_windows(self, X):\n",
        "        \"\"\"\n",
        "        Sliding Windows Characterization.\n",
        "        INPUT\n",
        "        -----\n",
        "          1. X: (3D array) set of EEG signals, shape (trials, channels, time_samples)\n",
        "        OUTPUT\n",
        "        ------\n",
        "          1. X_w: (4D array) shape (trials, channels, window_time_samples, number_of_windows)\n",
        "        \"\"\"\n",
        "        window_lenght = int(self.sfreq * self.vwt[0, 1] - self.sfreq * self.vwt[0, 0])\n",
        "        X_w = np.zeros((X.shape[0], X.shape[1], window_lenght, self.vwt.shape[0]))\n",
        "        for w in np.arange(self.vwt.shape[0]):\n",
        "            X_w[:, :, :, w] = X[\n",
        "                :,\n",
        "                :,\n",
        "                int(self.sfreq * self.vwt[w, 0]) : int(self.sfreq * self.vwt[w, 1]),\n",
        "            ]\n",
        "        return X_w\n",
        "\n",
        "    # ------------------------------------------------------------------------------\n",
        "    def fit(self, X, y=None):\n",
        "        \"\"\"\n",
        "        fit.\n",
        "        INPUT\n",
        "        -----\n",
        "          1. X: (3D array) set of EEG signals, shape (trials, channels, time_samples)\n",
        "          2. y: (1D array) target labels. Default=None\n",
        "        OUTPUT\n",
        "        ------\n",
        "          1. None\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    # ------------------------------------------------------------------------------\n",
        "    def transform(self, X, y=None):\n",
        "        \"\"\"\n",
        "        Time frequency representation of EEG signals.\n",
        "        INPUT\n",
        "        -----\n",
        "          1. X: (3D array) set of EEG signals, shape (trials, channels, times)\n",
        "        OUTPUT\n",
        "        ------\n",
        "          1. X_wf: (5D array) Time-frequency representation of EEG signals, shape (trials, channels, window_time_samples, number_of_windows, frequency_bands)\n",
        "        \"\"\"\n",
        "        self._validation_param()  # Validate sfreq, f_freq, vwt\n",
        "\n",
        "        # Avoid edge effects of digital filter, 1st:fbk, 2th:vwt\n",
        "        if self.flag_f_bank:\n",
        "            X_f = self._filter_bank(X)\n",
        "        else:\n",
        "            X_f = X[:, :, :, np.newaxis]\n",
        "\n",
        "        if self.flag_vwt:\n",
        "            X_wf = []\n",
        "            for f in range(X_f.shape[3]):\n",
        "                X_wf.append(self._sliding_windows(X_f[:, :, :, f]))\n",
        "            X_wf = np.stack(X_wf, axis=-1)\n",
        "        else:\n",
        "            X_wf = X_f[:, :, :, np.newaxis, :]\n",
        "\n",
        "        return X_wf\n",
        "\n",
        "\n",
        "# plot eeg\n",
        "def plot_eeg(X, tv, ax, channels, esp=2, title=None):\n",
        "    # X in CH x Samples\n",
        "    n_canales = X.shape[0]\n",
        "\n",
        "    for ch in range(n_canales):  # canales\n",
        "        xx = X[ch]\n",
        "        xx = xx - np.mean(xx)\n",
        "        xx = xx / np.max(abs(xx))\n",
        "        ax.plot(\n",
        "            tv, xx + (ch * esp), label=channels[ch]\n",
        "        )  # Desplazamos cada canal para visualización\n",
        "    ax.set_yticks(range(0, esp * n_canales, esp), channels)  # Etiquetas en el eje Y\n",
        "    ax.set_xlabel(\"Tiempo [s]\")\n",
        "    ax.set_ylabel(\"Canales EEG [$\\mu$V]\")\n",
        "    ax.set_title(title)\n",
        "    ax.grid(True)\n",
        "    ax.set_xlim([min(tv) - 0.01, max(tv) + 0.01])\n",
        "    ax.set_ylim([-esp, n_canales * esp + 0.01])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "136a8b50",
      "metadata": {},
      "source": [
        "**Protocol and montage.** Establish the test protocol and EEG montage configuration. Describe the data acquisition protocol and the montage used.\n",
        "\n",
        "\n",
        "<p align=\"center\">\n",
        "<img src=\"https://www.mdpi.com/diagnostics/diagnostics-13-01122/article_deploy/html/images/diagnostics-13-01122-g001.png\" alt=\"Motor imagery trial structure\" style=\"max-width:50%; width:85%;\">\n",
        "</p>\n",
        "\n",
        "\n",
        "<p align=\"center\">\n",
        "<img src=\"https://www.mdpi.com/applsci/applsci-14-11208/article_deploy/html/images/applsci-14-11208-g001.png\" alt=\"EEG montage diagram\" style=\"max-width:50%; width:85%;\">\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "865bd53e",
      "metadata": {},
      "outputs": [],
      "source": [
        "channels = [\n",
        "    \"Fp1\",\n",
        "    \"Fpz\",\n",
        "    \"Fp2\",\n",
        "    \"AF7\",\n",
        "    \"AF3\",\n",
        "    \"AFz\",\n",
        "    \"AF4\",\n",
        "    \"AF8\",\n",
        "    \"F7\",\n",
        "    \"F5\",\n",
        "    \"F3\",\n",
        "    \"F1\",\n",
        "    \"Fz\",\n",
        "    \"F2\",\n",
        "    \"F4\",\n",
        "    \"F6\",\n",
        "    \"F8\",\n",
        "    \"FT7\",\n",
        "    \"FC5\",\n",
        "    \"FC3\",\n",
        "    \"FC1\",\n",
        "    \"FCz\",\n",
        "    \"FC2\",\n",
        "    \"FC4\",\n",
        "    \"FC6\",\n",
        "    \"FT8\",\n",
        "    \"T7\",\n",
        "    \"C5\",\n",
        "    \"C3\",\n",
        "    \"C1\",\n",
        "    \"Cz\",\n",
        "    \"C2\",\n",
        "    \"C4\",\n",
        "    \"C6\",\n",
        "    \"T8\",\n",
        "    \"TP7\",\n",
        "    \"CP5\",\n",
        "    \"CP3\",\n",
        "    \"CP1\",\n",
        "    \"CPz\",\n",
        "    \"CP2\",\n",
        "    \"CP4\",\n",
        "    \"CP6\",\n",
        "    \"TP8\",\n",
        "    \"P9\",\n",
        "    \"P7\",\n",
        "    \"P5\",\n",
        "    \"P3\",\n",
        "    \"P1\",\n",
        "    \"Pz\",\n",
        "    \"P2\",\n",
        "    \"P4\",\n",
        "    \"P6\",\n",
        "    \"P8\",\n",
        "    \"P10\",\n",
        "    \"PO7\",\n",
        "    \"PO3\",\n",
        "    \"POz\",\n",
        "    \"PO4\",\n",
        "    \"PO8\",\n",
        "    \"O1\",\n",
        "    \"Oz\",\n",
        "    \"O2\",\n",
        "    \"Iz\",\n",
        "]\n",
        "\n",
        "areas = {\n",
        "    \"Frontal\": [\"Fpz\", \"AFz\", \"Fz\", \"FCz\"],\n",
        "    \"Frontal Right\": [\n",
        "        \"Fp2\",\n",
        "        \"AF4\",\n",
        "        \"AF8\",\n",
        "        \"F2\",\n",
        "        \"F4\",\n",
        "        \"F6\",\n",
        "        \"F8\",\n",
        "    ],\n",
        "    \"Central Right\": [\n",
        "        \"FC2\",\n",
        "        \"FC4\",\n",
        "        \"FC6\",\n",
        "        \"FT8\",\n",
        "        \"C2\",\n",
        "        \"C4\",\n",
        "        \"C6\",\n",
        "        \"T8\",\n",
        "        \"CP2\",\n",
        "        \"CP4\",\n",
        "        \"CP6\",\n",
        "        \"TP8\",\n",
        "    ],\n",
        "    \"Posterior Right\": [\n",
        "        \"P2\",\n",
        "        \"P4\",\n",
        "        \"P6\",\n",
        "        \"P8\",\n",
        "        \"P10\",\n",
        "        \"PO4\",\n",
        "        \"PO8\",\n",
        "        \"O2\",\n",
        "    ],\n",
        "    #'Central': ['Cz'],\n",
        "    \"Posterior\": [\n",
        "        \"CPz\",\n",
        "        \"Pz\",\n",
        "        \"Cz\",\n",
        "        \"POz\",\n",
        "        \"Oz\",\n",
        "        \"Iz\",\n",
        "    ],\n",
        "    \"Posterior Left\": [\n",
        "        \"P1\",\n",
        "        \"P3\",\n",
        "        \"P5\",\n",
        "        \"P7\",\n",
        "        \"P9\",\n",
        "        \"PO3\",\n",
        "        \"PO7\",\n",
        "        \"O1\",\n",
        "    ],\n",
        "    \"Central Left\": [\n",
        "        \"FC1\",\n",
        "        \"FC3\",\n",
        "        \"FC5\",\n",
        "        \"FT7\",\n",
        "        \"C1\",\n",
        "        \"C3\",\n",
        "        \"C5\",\n",
        "        \"T7\",\n",
        "        \"CP1\",\n",
        "        \"CP3\",\n",
        "        \"CP5\",\n",
        "        \"TP7\",\n",
        "    ],\n",
        "    \"Frontal Left\": [\n",
        "        \"Fp1\",\n",
        "        \"AF3\",\n",
        "        \"AF7\",\n",
        "        \"F1\",\n",
        "        \"F3\",\n",
        "        \"F5\",\n",
        "        \"F7\",\n",
        "    ],\n",
        "}\n",
        "\n",
        "arcs = [\n",
        "    #'hemispheres',\n",
        "    \"areas\",\n",
        "    \"channels\",\n",
        "]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d0e4c8b",
      "metadata": {},
      "source": [
        "**Data paths.** Define the path and parameters for loading the EEG data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e6d8bd6",
      "metadata": {},
      "outputs": [],
      "source": [
        "db = GIGA_MI_ME(\"/kaggle/input/giga-science-gcpds/GIGA_MI_ME\")\n",
        "# ti = 0\n",
        "# tf = 7\n",
        "new_fs = 256.0\n",
        "load_args = dict(\n",
        "    db=db,\n",
        "    eeg_ch_names=channels,\n",
        "    fs=db.metadata[\"sampling_rate\"],\n",
        "    # f_bank = np.asarray([[4., 40.]]),\n",
        "    # vwt = np.asarray([[ti, tf]]), #2.5 - 5 MI\n",
        "    new_fs=new_fs,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6cdad35f",
      "metadata": {},
      "source": [
        "**Loading.** Load the data for the desired participant.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d78e16a",
      "metadata": {},
      "outputs": [],
      "source": [
        "sbj = 5\n",
        "X, y = load_GIGA(sbj=sbj, **load_args)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72b92453",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\n",
        "    f\"X con {X.shape[0]} intentos; {X.shape[1]} canales; {X.shape[2]} muestras No. de segundos {X.shape[2] / new_fs}\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c99848e5",
      "metadata": {},
      "outputs": [],
      "source": [
        "X.shape\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae051c86",
      "metadata": {},
      "source": [
        "**Batch loading.** If you want to load data for all participants, iterate through the subject list so each one is loaded individually depending on the task.\n",
        "\n",
        "```python\n",
        "for sbj in sbj_list:\n",
        "    X, y = load_GIGA(sbj=sbj, **load_args)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eaac268c",
      "metadata": {},
      "source": [
        "**Time-domain visualization.** Visualize EEG signals in the time domain.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e763b0b5",
      "metadata": {},
      "outputs": [],
      "source": [
        "# graficar canales promedio\n",
        "trial = 0\n",
        "ti = 0  # ti\n",
        "tf = 7  # tf\n",
        "tv = np.arange(ti, tf, 1 / new_fs)\n",
        "\n",
        "# Señal cruda\n",
        "fig, ax = plt.subplots(1, 1, figsize=(8, 8), sharex=True)\n",
        "# Graficar cada canal en un subplot banda respectiva\n",
        "\n",
        "plot_eeg(X[trial], tv, ax=ax, channels=channels, title=\"EEG original\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6890a18a",
      "metadata": {},
      "source": [
        "**Exercise 2.** Discuss the preceding plot.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f0e8a79",
      "metadata": {},
      "source": [
        "**Note.** Discuss what brain rhythms consist of.\n",
        "\n",
        "<p align=\"center\"><img src=\"https://cdn.shopify.com/s/files/1/0348/7053/files/storage.googleapis.com-486681944373284_61cb9936-f6c2-493d-8402-3426d7f5a049_1024x1024.jpg?v=1689309340\" alt=\"Brain rhythm bands\" style=\"max-width:40%; width:65%;\"></p>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6dbae7d1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# filtramos trials completos en ritmos cerebrales utilizando filtros IIR\n",
        "\n",
        "\n",
        "f_bank = np.array([[0.5, 4.0], [4.0, 8.0], [8.0, 13.0], [13.0, 32.0], [32.0, 100.0]])\n",
        "vwt = np.asarray([[ti, tf]])  # 2.5 - 5 MI 0 - 7 trial completo\n",
        "tf_repr = TimeFrequencyRpr(sfreq=new_fs, f_bank=f_bank)\n",
        "\n",
        "Xrc = np.squeeze(tf_repr.transform(X))\n",
        "\n",
        "Xrc.shape\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d91636d0",
      "metadata": {},
      "source": [
        "**Exercise 3.** Explain how each of the five dimensions of the Xrc array was computed.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "008e0f18",
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "ritmo = [\"delta\", \"theta\", \"alpha\", \"beta\", \"gamma\"]\n",
        "trial = 0\n",
        "n_trials, n_canales, n_muestras, n_bands = Xrc.shape  # Simulación de datos\n",
        "\n",
        "esp = 2  # espaciado canales\n",
        "fig, ax = plt.subplots(5, 1, figsize=(8, 40))\n",
        "# Graficar cada canal en un subplot banda respectiva\n",
        "for b in range(f_bank.shape[0]):  # bandas\n",
        "    plot_eeg(\n",
        "        Xrc[trial, :, :, b],\n",
        "        tv,\n",
        "        ax=ax[b],\n",
        "        channels=channels,\n",
        "        title=f\"EEG Filtrado {f_bank[b, 0]}-{f_bank[b, 1]} [Hz] -- Ritmo: {ritmo[b]}\",\n",
        "    )\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56486adc",
      "metadata": {},
      "source": [
        "**Frequency-domain visualization.** Visualize EEG signals in the frequency domain.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0560e137",
      "metadata": {},
      "outputs": [],
      "source": [
        "# señal orignal\n",
        "Xwo = np.fft.rfft(X, axis=-1)\n",
        "vfreq = np.fft.rfftfreq(X.shape[2], 1 / new_fs)\n",
        "\n",
        "Xwo.shape\n",
        "plt.plot(vfreq, 20 * np.log10(np.abs(Xwo[trial])).T)\n",
        "plt.xlabel(\"Frecuencia [Hz]\")\n",
        "plt.ylabel(\"Magnitud [dB]\")\n",
        "plt.title(\"Eespectro Señal EEG original\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0af24796",
      "metadata": {},
      "source": [
        "**Exercise 4.** Discuss the preceding plot.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbd3a649",
      "metadata": {},
      "outputs": [],
      "source": [
        "# espectro señales filtradas\n",
        "Xwb = np.fft.rfft(Xrc, axis=2)\n",
        "\n",
        "Xwb.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fea2d321",
      "metadata": {},
      "outputs": [],
      "source": [
        "# espectro señales filtradas por bandas - ritmos cerebrales\n",
        "\n",
        "fig, ax = plt.subplots(5, 1, figsize=(8, 40))\n",
        "# Graficar cada canal en un subplot banda respectiva\n",
        "for b in range(f_bank.shape[0]):  # bandas\n",
        "    ax[b].plot(vfreq, 20 * np.log10(np.abs(Xwb[trial, :, :, b])).T)\n",
        "    ax[b].set_xlabel(\"Frecuencia [Hz]\")\n",
        "    ax[b].set_ylabel(\"Magnitud [dB]\")\n",
        "    ax[b].set_title(\n",
        "        f\"Esepctro EEG Filtrado {f_bank[b, 0]}-{f_bank[b, 1]} [Hz] -- Ritmo: {ritmo[b]}\"\n",
        "    )\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8bf7848d",
      "metadata": {},
      "source": [
        "**Exercise 5.** Discuss the plots.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ebf7881",
      "metadata": {},
      "source": [
        "**Spectrograms.** Visualize spectrograms. Review what the Short-Time Fourier Transform is.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef5cb418",
      "metadata": {},
      "outputs": [],
      "source": [
        "# estimar stft con ventanas de nperseg puntos sobre eje temporal en EEG original\n",
        "from scipy.signal import stft  #\n",
        "\n",
        "nperseg = 0.5 * new_fs  # longitud ventas en muestras\n",
        "vfs, t, Xstft = stft(X, fs=new_fs, nperseg=nperseg, axis=2)\n",
        "Xstft = 20 * np.log10(abs(Xstft))\n",
        "\n",
        "# graficar stft para un trial y un canal\n",
        "trail = 0\n",
        "chi = channels.index(\"C4\")\n",
        "\n",
        "fig, ax = plt.subplots(2, 1, figsize=(10, 6))\n",
        "\n",
        "ax[1].plot(tv, X[trail, chi, :])\n",
        "ax[1].set_ylabel(\"Amp. [$\\mu$ V]\")\n",
        "im = ax[0].pcolormesh(t, vfs, Xstft[trail, chi])\n",
        "fig.colorbar(im, ax=ax[0], orientation=\"horizontal\", pad=0.2)\n",
        "plt.gca()\n",
        "plt.xlabel(\"t [seg]\")\n",
        "plt.ylabel(\"f [Hz]\")\n",
        "ax[0].set_title(f\"Esepctrograma EEG Original -- Ch = {channels[chi]}\")\n",
        "print(Xstft.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa396aa4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# estimar stft con ventanas de nperseg puntos sobre eje temporal en EEG original\n",
        "b = 2\n",
        "vfs, t, Xstftb = stft(Xrc, fs=new_fs, nperseg=nperseg, axis=2)\n",
        "Xstftb = 20 * np.log10(abs(Xstftb))\n",
        "\n",
        "print(Xstftb.shape)\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots(2, 1, figsize=(10, 6))\n",
        "ax[1].plot(tv, Xrc[trail, chi, :, b])\n",
        "ax[1].set_ylabel(\"Amp. [$\\mu$ V]\")\n",
        "im = ax[0].pcolormesh(t, vfs, Xstftb[trail, chi, :, b, :])\n",
        "fig.colorbar(im, ax=ax[0], orientation=\"horizontal\", pad=0.2)\n",
        "plt.gca()\n",
        "plt.xlabel(\"t [seg]\")\n",
        "plt.ylabel(\"f [Hz]\")\n",
        "ax[0].set_title(\n",
        "    f\"Esepctrograma EEG Filtrado {f_bank[b, 0]}-{f_bank[b, 1]} [Hz] -- Ritmo: {ritmo[b]} -- Ch = {channels[chi]}\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d447b97",
      "metadata": {},
      "source": [
        "**Exercise 6.** Present the STFT plots for different channels across the five brain rhythms and discuss.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f8268ca",
      "metadata": {},
      "source": [
        "**10–20 montage visualization.** Visualize EEG signals on the 10-20 montage.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ada5ecf7",
      "metadata": {},
      "outputs": [],
      "source": [
        "import mne\n",
        "\n",
        "# Cargar el montaje estándar\n",
        "easycap_montage = mne.channels.make_standard_montage(\"standard_1020\")\n",
        "\n",
        "\n",
        "# Crear un montaje personalizado con los electrodos seleccionados\n",
        "custom_pos = {ch: easycap_montage.get_positions()[\"ch_pos\"][ch] for ch in channels}\n",
        "custom_montage = mne.channels.make_dig_montage(ch_pos=custom_pos, coord_frame=\"head\")\n",
        "\n",
        "# Mostrar el montaje personalizado\n",
        "custom_montage.plot(show_names=True)\n",
        "fig = custom_montage.plot(kind=\"3d\", show_names=True, show=False)\n",
        "fig.gca().view_init(azim=70, elev=15)  # Ajustar la vista 3D\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bcae68de",
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -U git+https://github.com/UN-GCPDS/python-gcpds.visualizations.git\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c90e9d80",
      "metadata": {},
      "source": [
        "**Topographic maps.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54f8e204",
      "metadata": {},
      "outputs": [],
      "source": [
        "from gcpds.visualizations.topoplots import topoplot\n",
        "\n",
        "\n",
        "trial = 150\n",
        "vec_topo_o = abs(X[trial, :]).mean(axis=-1)\n",
        "vec_topo_b = abs(Xrc[trial, :, :, :]).mean(axis=1)\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots(1, 6, figsize=(20, 10))\n",
        "topoplot(\n",
        "    vec_topo_o,\n",
        "    channels,\n",
        "    contours=3,\n",
        "    cmap=\"Reds\",\n",
        "    names=channels,\n",
        "    sensors=False,\n",
        "    ax=ax[0],\n",
        "    show=False,\n",
        "    vlim=(min(vec_topo_o), max(vec_topo_o)),\n",
        ")\n",
        "\n",
        "for b in range(f_bank.shape[0]):\n",
        "    vec_ = vec_topo_b[:, b]\n",
        "    topoplot(\n",
        "        vec_,\n",
        "        channels,\n",
        "        contours=3,\n",
        "        cmap=\"Reds\",\n",
        "        names=channels,\n",
        "        sensors=False,\n",
        "        ax=ax[b + 1],\n",
        "        show=False,\n",
        "        vlim=(min(vec_), max(vec_)),\n",
        "    )\n",
        "    ax[b + 1].set_title(ritmo[b])\n",
        "\n",
        "ax[0].set_title(f\"EEG-suj={sbj}-trial={trial}\")\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67671850",
      "metadata": {},
      "source": [
        "**Exercise 7.** Discuss.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1424a89b",
      "metadata": {},
      "source": [
        "**Common Spatial Patterns.** Investigate what Common Spatial Patterns (CSP) are and their application to EEG signal processing.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1086bdd",
      "metadata": {},
      "outputs": [],
      "source": [
        "import mne\n",
        "from mne.decoding import CSP\n",
        "\n",
        "# Instancia del objeto CSP\n",
        "n_components = 2\n",
        "csp = CSP(n_components=n_components, log=True, transform_into=\"average_power\")\n",
        "# Ajuste y transformación de los datos\n",
        "csp_data = csp.fit_transform(X.astype(np.float64), y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7641650",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"CSP Transformado Shape:\", csp_data.shape)\n",
        "plt.scatter(csp_data[:, 0], csp_data[:, 1], c=y)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab035c71",
      "metadata": {},
      "outputs": [],
      "source": [
        "# EEG original\n",
        "fig, ax = plt.subplots(1, n_components, figsize=(5, 5))\n",
        "for cc in range(n_components):\n",
        "    vec_ = np.abs(csp.filters_[cc])\n",
        "    topoplot(\n",
        "        vec_,\n",
        "        channels,\n",
        "        contours=3,\n",
        "        cmap=\"Reds\",\n",
        "        names=channels,\n",
        "        sensors=False,\n",
        "        ax=ax[cc],\n",
        "        show=False,\n",
        "        vlim=(min(vec_), max(vec_)),\n",
        "    )\n",
        "    ax[cc].set_title(f\"CSP {cc + 1}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bddb1c81",
      "metadata": {},
      "outputs": [],
      "source": [
        "# lectura de datos\n",
        "sbj = 14\n",
        "X, y = load_GIGA(sbj=sbj, **load_args)\n",
        "\n",
        "f_bank = np.array([[0.5, 4.0], [4.0, 8.0], [8.0, 13.0], [13.0, 32.0], [32.0, 100.0]])\n",
        "vwt = np.array(\n",
        "    [[0.25, 1.75], [1.5, 3], [2.75, 4.25], [4, 5.5], [5.25, 6.75]]\n",
        ")  # 2.5 - 5 MI 0 - 7 trial completo\n",
        "tf_repr = TimeFrequencyRpr(sfreq=new_fs, f_bank=f_bank, vwt=vwt)\n",
        "X_ = np.squeeze(tf_repr.transform(X))\n",
        "X_.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49ee68e1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# csp por ventanas y ritmos\n",
        "# Definir las dimensiones del arreglo\n",
        "ritmos_ = f_bank.shape[0]\n",
        "ventanas_ = vwt.shape[0]\n",
        "n_comp = 2\n",
        "# Inicializar el arreglo vacío con listas anidadas\n",
        "csp_M = [[None for _ in range(ventanas_)] for _ in range(ritmos_)]\n",
        "csp_filters_ = np.zeros(\n",
        "    (ritmos_, ventanas_, X_.shape[1], X_.shape[1])\n",
        ")  # ritmos ventanas Ch\n",
        "Xcsp_ = np.zeros((X_.shape[0], n_comp, ritmos_, ventanas_))\n",
        "\n",
        "for i in range(ritmos_):\n",
        "    for j in range(ventanas_):\n",
        "        print(f\"CSP ritmo {f_bank[i]} -- ventana {vwt[j]}...\")\n",
        "        csp_M[i][j] = CSP(n_components=n_comp, log=True, transform_into=\"average_power\")\n",
        "        Xcsp_[:, :, i, j] = csp.fit_transform(X_[:, :, :, j, i].astype(np.float64), y)\n",
        "        csp_filters_[i, j, :] = np.abs(csp.filters_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bfc2171a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# graficar topomaps\n",
        "fig, ax = plt.subplots(ritmos_, ventanas_, figsize=(12, 12))\n",
        "\n",
        "for i in range(ritmos_):\n",
        "    for j in range(ventanas_):\n",
        "        vec_ = csp_filters_[i, j, 0]\n",
        "        vec_ = vec_ / max(vec_)\n",
        "        topoplot(\n",
        "            vec_,\n",
        "            channels,\n",
        "            contours=3,\n",
        "            cmap=\"Reds\",\n",
        "            names=None,\n",
        "            sensors=False,\n",
        "            ax=ax[i, j],\n",
        "            show=False,\n",
        "            vlim=(min(vec_), max(vec_)),\n",
        "        )\n",
        "    ax[i, 0].set_ylabel(ritmo[i], fontsize=20)\n",
        "for j in range(ventanas_):\n",
        "    ax[0, j].set_title(f\"{vwt[j, 0]}--{vwt[j, 1]} [s]\", fontsize=15)\n",
        "\n",
        "plt.subplots_adjust(hspace=-0.025, wspace=-0.025)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f398fa7f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# scatters\n",
        "fig, ax = plt.subplots(ritmos_, ventanas_, figsize=(12, 12))\n",
        "\n",
        "for i in range(ritmos_):\n",
        "    for j in range(ventanas_):\n",
        "        ax[i, j].scatter(Xcsp_[:, 0, i, j], Xcsp_[:, 1, i, j], c=y)\n",
        "        ax[i, j].set_xticks([])\n",
        "        ax[i, j].set_yticks([])\n",
        "    ax[i, 0].set_ylabel(ritmo[i], fontsize=20)\n",
        "for j in range(ventanas_):\n",
        "    ax[0, j].set_title(f\"{vwt[j, 0]}--{vwt[j, 1]} [s]\", fontsize=15)\n",
        "\n",
        "plt.subplots_adjust(hspace=0.1, wspace=0.1)\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
